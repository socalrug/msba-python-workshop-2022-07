{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subsetting `DataFrames`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In this section, we'll cover\n",
    "\n",
    "* What subsetting is and why it's in important tool for working with data\n",
    "* How to select specific columns from a `DataFrame`\n",
    "* How to filter specific rows using conditional expressions\n",
    "* `pandas` specific syntax for subsetting and filtering data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is Subsetting?\n",
    "\n",
    "One of the most common and fundamental tasks you'll perform while working with data is *subsetting* the data you're working with.  Subsetting is simply the action of focusing in on the pieces of the data that you care about or need to access.  Subsetting isn't something that you'll do just once; you'll often subset your data over and over during the course of an analysis to understand what's in the data, drill into specific pieces of the data, and look for potential data problems (just to name a few).  Becoming an effective subsetter is an important component to becoming a proficient data analyst.\n",
    "\n",
    "In the case of tabular data (i.e. a `pandas` `DataFrame`), subsetting can be divided into to main categories\n",
    "\n",
    "* Selecting specific columns\n",
    "* Filtering to specific rows\n",
    "\n",
    "In this section, we'll cover both of these case.  But before that, let's load up the penguins data set to work with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remember that  you need to import the pandas package before you can use it\n",
    "import pandas as pd\n",
    "\n",
    "# Read the penguins dataset (provideed by Allison Horst)\n",
    "# https://github.com/allisonhorst/palmerpenguins\n",
    "penguins = pd.read_csv(\"https://raw.githubusercontent.com/allisonhorst/palmerpenguins/master/inst/extdata/penguins.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting Specific Columns with `pandas`\n",
    "\n",
    "Selecting specific columns from your data is typically used to help focus in on the main pieces of data you care about.  Imagine your data set has 100's of columns, but you only care about a handful of them.  Keeping those additional columns throughout your analysis makes it difficult to review results (i.e. when you print out your data table) and can add additional, unneeded complexity to the problem you're working on.\n",
    "\n",
    "Another common use case for selecting specific columns is when you want to select a single column of data, and perform some action with it.  For example, you might be interested in the mean value of one of the columns.  Here, you might first *select* that column to get the underlying values, then calculate the mean value.\n",
    "\n",
    "There are several ways to select a single column from a `DataFrame`, but one of the most useful and straight forward ways is to use the column's name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to know the column names first!\n",
    "list(penguins.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the species column\n",
    "# Use the square brackets, [ ], along with a column name\n",
    "penguins[\"species\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the unique set of species in the data\n",
    "penguins[\"species\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the maximum body mass\n",
    "penguins[\"body_mass_g\"].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's also possible to select multiple columns at once (e.g. if you want to focus in on only a subset of the columns).  The code syntax is similar to the single column case, but here, we need to first construct a Python list of the column names we're interested, then subset with that instead of the single column name we used before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get just the species, island and body mass\n",
    "colNamesSelected = [\"species\", \"island\", \"body_mass_g\"]\n",
    "penguins[colNamesSelected]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In practice, you might not always want to created a separate variable of the column names before doing the subsetting.  You can just put the Python list inside the square brackets directly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "penguins[[\"species\", \"island\", \"body_mass_g\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note in the code above that we don't have a new \"double bracket\", `[[`,  operator here.  The inner brackets define the Python list (standardy Python syntax), while the outer brackets are doing the subsetting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interestingly, you can also perform operations after selecting multiple columns (or on `DataFrames` generally) like we did for the single column case:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code will get the max values for each of the selected columns\n",
    "mvs = penguins[[\"bill_length_mm\", \"bill_depth_mm\", \"flipper_length_mm\", \"body_mass_g\"]].max()\n",
    "mvs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can also apply to the entire DataFrame\n",
    "penguins.max(numeric_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering Specific Rows\n",
    "\n",
    "Subsetting to specific rows is similar in spirit to selecting columns (i.e. getting entire rows of data vs. getting entire columns of data), but adds an additional powerful feature: the ability to select rows based on the underlying data values.  For column subsetting, we simply used the names of the columns to get a subset.  That's also possible with row subsetting (using a row label), but you can also define the row subsetting based upon conditions in the data.\n",
    "\n",
    "Image the case where you only want to get the data for the Gentoo species of penguin, or penguins above a certain body mass, or a combination of both.  Row subsetting (filtering) allows you to do that.\n",
    "\n",
    "There are several ways to filter rows in your data, but one of the most useful is to construct a list *boolean* (true or false) values based on the condition you're interested in.  This list should be exactly the same length as the total number of rows in your data (before filtering), and a value of `true` means to keep that row, and a value of `false` say to get rid of it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get only the Gentoo penguin data\n",
    "# First make our boolean list, one value for each row in our data noting which are Gentoo\n",
    "isGentoo = penguins[\"species\"] == \"Gentoo\"\n",
    "isGentoo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "penguins[isGentoo]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just like in the example above were we selected multiple columns with a Python list inside of the subset brackets, you can also place the conditional expression (which defined the boolean list) directly inside the subsetting brackets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "penguins[penguins[\"species\"] == \"Gentoo\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the penguins greater than 5000 g\n",
    "penguins[penguins[\"body_mass_g\"] > 5000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that we used the same bracket operator, `[ ]`, that we used with column selection.  `pandas` understands how to deal with these different cases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's possible to combine multiple boolean expressions to get more complex filtering.  First, you'll need to wrap each expression in `( )`. Second, you'll need to combine them with boolean operators, `&` and `|`.  Note that you can't use Python keywords `and` or `or` here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the Gentoo penguins that are greater than 5000g\n",
    "penguins[(penguins[\"species\"] == \"Gentoo\") & (penguins[\"body_mass_g\"] > 5000)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One important shortcut to simplifying complex boolean expressions that check if a given value is contained in a specific set of values is to use the `isin` (read as \"is in\") function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get only the Adelie and Gentoo penguin data\n",
    "penguins[penguins[\"species\"].isin([\"Adelie\", \"Gentoo\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is equivalent to the more complex (and verbose) version\n",
    "penguins[(penguins[\"species\"] == \"Adelie\") | (penguins[\"species\"] == \"Gentoo\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another useful filtering operation is to remove rows with missing data.  We can see some of those cases in the table above occuring where values are `NaN`.  There is a function specifically for this task: `notna`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only get the data where the body mass is NOT missing\n",
    "penguins[penguins[\"body_mass_g\"].notna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subset Specific Rows and Columns at the Same Time\n",
    "\n",
    "It's also possible to subset both rows and columns in a single expression, but we'll have to use slightly different syntax since using just the selection brackets, `[ ]` isn't sufficient (recall we used the same selection brackets to subset to columns OR rows).  In this case, we need to use the `loc` or `iloc` operators before the selection brackets, and specify both row and column selections separated by a `,`.  Let's review this with a specific example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the sexes of the Gentoo penguins greater than 5000 g\n",
    "penguins.loc[(penguins[\"species\"] == \"Gentoo\") & (penguins[\"body_mass_g\"] > 5000), \"sex\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `loc` operator is used when you specify selections using column names, row labels, or conditional expressions.\n",
    "\n",
    "If instead you want to get rows or columns by numeric position in the data (e.g. I want the first 10 rows with the last 3 columns), use `iloc`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Reminder: Recall that Python start counting at 0, and the slice operator `:` ranges from the first value inclusive to the last value exclusive.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the first 10 rows, and all the columns\n",
    "# if you don't specify the rows (second index of iloc), you get all the columns\n",
    "penguins.iloc[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the first 10 rows and and the last 3 columns\n",
    "penguins.iloc[0:10, 5:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While subsetting by location (i.e. with `iloc`) is good to know, your code will often make more sense when subsetting is done using explicit column names and conditional expressions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Points\n",
    "\n",
    "* Subsetting is a fundamental data manipulation operation that you'll be doing frequently.\n",
    "* There are two main types of subsetting with tabular data in `pandas`: selecting specific columns, and filtering specific rows.\n",
    "* Subsetting is accomplished using selection brackets, `[ ]`.\n",
    "* Subsetting to specific columns is conveniently done by specifying column names.\n",
    "* Subsetting to specific rows is often done by specifying a boolean expression (condition).\n",
    "* You can subset rows and columns at the same time using the `loc` and `iloc` operators."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.5 - rstudio",
   "language": "python",
   "name": "rstudio-user-3.9.5"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
